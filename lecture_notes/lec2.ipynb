{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecutre 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image classification is a core task in Computer Vision.\n",
    "\n",
    "## Problem: Semantic Gap\n",
    "\n",
    "If given an image of a cat, computer sees a giant grid of numbers, wheras we see a cat. This is the semantic problem.\n",
    "\n",
    "As well, if we took a different picture of this cat, all the pixel numbers would be different, but still be of the same cat.\n",
    "\n",
    "More challenges: illumination, deformation, occlusion (seeing only parts of an object), background clutter (bg looks similar to object), interclass variation (cats have different shapes, colours, and sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Attempt\n",
    "def classify_image(image):\n",
    "    # some magic here?\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous attempts\n",
    "1. find edges of an image\n",
    "2. find corners and categorize them\n",
    "3. get a label using an explicit set of rules\n",
    "\n",
    "This doesn't work well.\n",
    "Super brittle, doesn't work for other objects. Thus, not scalable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Driven Approach\n",
    "1. Collect a dataset of images and labels\n",
    "2. Use ML to train a classifier\n",
    "3. Evaluate the classifier on new images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(images, labels):\n",
    "    # Machine learning\n",
    "    return model \n",
    "    \n",
    "def predict(model, test_images):\n",
    "    # Use model to predict labels\n",
    "    return test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our API has changed. One that trains our model, one that uses the model to make a prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First classifier: Nearest Neighbour\n",
    "An ex of a simple classifer\n",
    "\n",
    "in our training step, we'll **memorize** all data and labels\n",
    "\n",
    "in our prediction, we'll predict the model of the most similar training image\n",
    "\n",
    "This will basically return an image that LOOKS visually similar. This however won't be super accurate, since from far away a white bg png of a cat would look similar to one of a lynx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we compare images?\n",
    "\n",
    "### L1 distance\n",
    "$$d_1 (I_1, I_2) = \\sum_{P} |I_1^p - I_2^p|$$\n",
    "\n",
    "compare individual pixels and add all pixel-wise absolute value differences. \n",
    "\n",
    "Here's an example of the implementation of the nearest neighbour classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighbour:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        ''' X is N x D where each row is an example. y is a 1-D of size N'''\n",
    "        # the nearest neighbour classifier simply remembers all the training data\n",
    "        self.Xtr = X\n",
    "        self.Ytr = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' X is N x D where each row is an example we wish to predict the label for '''\n",
    "        num_test = X.shape[0]\n",
    "        # let's make sure that the output type matches the input type\n",
    "        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
    "\n",
    "        # loop over all test rows\n",
    "        for i in xrange(num_test):\n",
    "            # find nearest training image to the ith test image\n",
    "            # using L1 distance \n",
    "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis =1)\n",
    "            min_index = np.argmin(distances) # get the index w smallest distance\n",
    "            Ypred[i] = self.ytr[min_index]  # predict the label of nearest example\n",
    "\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. with N examples, how fast are training and prediction?\n",
    "\n",
    "A. Train O(1), predict O(N)\n",
    "\n",
    "This is actually bad, we want classifiers that are fast at prediction, slow for training is OK.\n",
    "\n",
    "Q. What does this look like?\n",
    "\n",
    "A. \n",
    "\n",
    "![nearest neighbour](../pics/neighbour.jpg)\n",
    "\n",
    "This is prone to error, because if there was 1 yellow dot in the middle of the green area, there would now be a yellow island that shouldn't relaly be there.\n",
    "\n",
    "\n",
    "This introduces the idea of: K-Nearest Neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours\n",
    "Instead of copying label from nearest neighbour, take the **majority vote** from K closest points.\n",
    "\n",
    "![k nearest neighbours](../pics/knn.jpg)\n",
    "As K increases, the decision boundaries become smoother and leads to better results.\n",
    "\n",
    "This will yield white regions though - regions where there was no majority amongst the k-nearest neighbours. \n",
    "You could take it further and just do a random guess in the white regions, but for now we'll just say there was no majority there. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different viewpoints\n",
    "1. Idea of high dimentional points in the plane\n",
    "2. Concrete images (pixels of img are high dimensional vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours: Distance Metrics\n",
    "\n",
    "We learned the L1 distance, AKA (Manhattan Distance).\n",
    "\n",
    "$$d_1(I_1, I_2) = \\sum_p |I_1^P - I_2^P|$$\n",
    "\n",
    "This function looks like a rotated square at origin\n",
    "\n",
    "We introduce a new distance metric:\n",
    "L2 (Euclidian) distance\n",
    "\n",
    "$$d_2(I_1, I_2) = \\sqrt{\\sum_p (I_1^P - I_2^P)^2}$$\n",
    "\n",
    "this function looks like a circle at origin\n",
    "\n",
    "\n",
    "By using different different distance metrics, you can generalize the knn classifier to many different types of data. \n",
    "\n",
    "e.g. classify pieces of text: \n",
    "only thing that needs to be done is to specify some distance function that can measure distances between two sentences. \n",
    "\n",
    "So, despite its simplicity, it's something you can always try for any problem.\n",
    "\n",
    "Play aroud with it here: http://vision.stanford.edu/teaching/cs231n-demos/knn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question becomes: how do you choose best K and best distance metric to use?\n",
    "\n",
    "These are hyperparameters: choices about the algorithm that we set rather than learn.\n",
    "\n",
    "These are problem dependent. Best approach is try them out and see what works best (guess and check).\n",
    "\n",
    "## Setting Hyperparameters:\n",
    "\n",
    "#### Idea 1: \n",
    "Choose hyperparameters that work best on the data. \n",
    "**This is bad.** K=1 always works perfectly on training data.\n",
    "We saw how bad it was when we plotted an island point in another region.\n",
    "\n",
    "#### Idea 2:\n",
    "Split data into **train** and **test**, choose hyperparameters that work best on test data.\n",
    "**This is bad**. We have idea how algorithm will perform on new data.\n",
    "\n",
    "#### Idea 3:\n",
    "Split data into train, val, and test; choose hyperparameters on val and evaluate on test.\n",
    "Better!\n",
    "Choose a training set, where you train with diff choices of hyperparams, evaluate these on the validation set. Choose best set of hyperparams on the validation set, and use it once on the test set.\n",
    "\n",
    "#### Idea 4: Cross-validation\n",
    "Split the data into **folds**, try each fold as validation and average the results.\n",
    "\n",
    "This is useful for small datasets, but not used too frequently in DL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you do this K-fold cross-validation, you can get plots that shows the accuracy of your model as a function of hyperparameters. This helps you determine your hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbour on images is **never used**\n",
    "- Very slow at test time\n",
    "- Distance metrics on pixels are not informative.\n",
    "\n",
    "## Curse of dimensionlity\n",
    "To densly cover pixels in a 3-d space, you exponentially need more data/images. you'll never have enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of k-Nearest Neighbours\n",
    "In **Image classification**, we start with a **training set** of images and labels, and must predict labels on the **test set**.\n",
    "\n",
    "The **K-nearest Neighbours** classifer predicts labels based on nearest training examples.\n",
    "\n",
    "Distance metric and K are **hyperparameters**.\n",
    "\n",
    "Choose hyperparameters using the **validation set**, only run on the test set once at the very end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classification\n",
    "Analogy: a neural network is like a tower of lego blocks.\n",
    "\n",
    "One of the most basic building blocks is this linear classifier.\n",
    "\n",
    "## Recall CIFAR 10\n",
    "50000 training images, each 32x32x3\n",
    "\n",
    "10000 test images.\n",
    "\n",
    "### Linear classifier is a parametric approach\n",
    "\n",
    "image --> $f(x, W)$ --> 10 numbers giving class scores\n",
    "\n",
    "$W$ = parameters or weights\n",
    "\n",
    "$$f(x, W) = Wx + b$$\n",
    "\n",
    "10x1    =    (10x3072) (3072x1), since x = 32x32x3 = 3072x1\n",
    "\n",
    "b is 10x1\n",
    "\n",
    "![lc_example](../pics/lc_ex.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained weights of linear classifiers make \"templates\" per class it needs to classify. So, when given class images of different orientations, it'll try and average all those out through one template. \n",
    "\n",
    "This is where linear classifiers fall short, and more complex models can compensate for this.\n",
    "\n",
    "You can also view linear classifiers as a series of a bunch of lines, where each line seperates one class from all the other lines.\n",
    "\n",
    "\n",
    "## Places where linear classifiers struggle\n",
    "- classifying even vs odd\n",
    "- multimodal situations (3 blobs of blue in a sea of red. hard to draw single line that seperate these regions), i.e. 1 class that can appear in different regions of space\n",
    "\n",
    "## How can we tell if this W is good or bad?\n",
    "Next lecture. \n",
    "Coming up:\n",
    "- loss function\n",
    "- optimization\n",
    "- convnets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "205a18728344f39db965b2d9cebb2d1ea3cf944444e8838c73d6b0832603cfd3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
